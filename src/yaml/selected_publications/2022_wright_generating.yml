abstract: Automated scientific fact checking is difficult due to the complexity of
  scientific language and a lack of significant amounts of training data, as annotation
  requires domain expertise. To address this challenge, we propose scientific claim
  generation, the task of generating one or more atomic and verifiable claims from
  scientific sentences, and demonstrate its usefulness in zero-shot fact checking
  for biomedical claims. We propose CLAIMGEN-BART, a new supervised method for generating
  claims supported by the literature, as well as KBIN, a novel method for generating
  claim negations. Additionally, we adapt an existing unsupervised entity-centric
  method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY.
  Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and
  CLAIMGEN-BART, coupled with KBIN, achieve up to 90% performance of fully supervised
  models trained on manually annotated claims and evidence. A rigorous evaluation
  study demonstrates significant improvement in generated claim and negation quality
  over existing baselines
authors:
- Dustin Wright
- David Wadden
- Kyle Lo
- Bailey Kuehl
- Arman Cohan
- Isabelle Augenstein
- Lucy Lu Wang
project: other
title: Generating Scientific Claims for Zero-Shot Scientific Fact Checking
url: https://www.semanticscholar.org/paper/7ff271856b6719cbeb5c5f1c7c46dc185b945d51
venue: In ACL 2022
year: 2022
