abstract: People primarily consult tables to conduct data analysis or answer specific
  questions. Text generation systems that can provide accurate table summaries tailored
  to users' information needs can facilitate more efficient access to relevant data
  insights. However, existing table-to-text generation studies primarily focus on
  converting tabular data into coherent statements, rather than addressing information-seeking
  purposes. In this paper, we define a new query-focused table summarization task,
  where text generation models have to perform human-like reasoning and analysis over
  the given table to generate a tailored summary, and we introduce a new benchmark
  named QTSumm for this task. QTSumm consists of 5,625 human-annotated query-summary
  pairs over 2,437 tables on diverse topics. Moreover, we investigate state-of-the-art
  models (i.e., text generation, table-to-text generation, and large language models)
  on the QTSumm dataset. Experimental results and manual analysis reveal that our
  benchmark presents significant challenges in table-to-text generation for future
  research.
authors:
- Yilun Zhao
- Zhenting Qi
- Linyong Nan
- Boyu Mi
- Yixin Liu
- Weijin Zou
- Simeng Han
- Xiangru Tang
- Yumo Xu
- Arman Cohan
- Dragomir R. Radev
project: other
title: 'QTSumm: A New Benchmark for Query-Focused Table Summarization'
url: https://www.semanticscholar.org/paper/beeaa3b353f0afeb2387f8336c052042a9b78cc0
venue: In ArXiv 2023
year: 2023
